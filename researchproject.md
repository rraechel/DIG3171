---
layout: default
title: Research Project
---  

# My Final Research Project  
[Digital Research Chatbot](https://share.chatling.ai/s/j6ZD2ALgDeTeVY7)

# Abstract
With the rise of advancing artificial intelligence and chatbots, one must question what the potential risks associated with using such resources are. The usage of these technologies is increasing everyday within the general population, from customer service to education and healthcare. While these tools offer a wide range of benefits, they also introduce many new cybersecurity risks that can affect all users. This research project focuses on the cybersecurity challenges associated with AI chatbots. Using the digital tool, Chatling, one can interact with the chatbot to grasp an understanding of the potential risks. This tool allows for the user to engage with the very topic that was researched and highlights the various ways it can be weaponized against users. 

Through research and interaction with specific chatbots, researchers have pinpointed where the main cybersecurity risks lie within artificial intelligence and chatbots. In ChatGPT alone, jailbreaking, social engineering attacks, phishing attacks, malware generation, and hallucination have been demonstrated (Charfeddine). While such tools have safeguards in place to prevent these issues, certain techniques such as jailbreaking and reverse psychology allow users to bypass this (Gupta 26). With AI being so accessible, cybercriminals are able to weaponize AI to create AI-driven attacks, some so advanced that typical cybersecurity measures are unable to detect these attacks (Nobles 8). In a research study, when asked about ChatGPT and other AI chatbots for daily usage such as work, majority of participants surveyed indicated they are likely or very likely to use such tools (Sebastian 6). In a different study, 80% of survey participants agreed that ChatGPT could be compromised and confidential material could be accessed, along with 89% agreeing that ChatGPT may have access to sensitive data that could potentially be misused (Alawida 21).

  The findings in this research project highlight the importance of understanding cybersecurity and the risks that come with the advancing technologies. Everyone is vulnerable to these attacks, whether they are engaging with AI and chatbots or not. Increasing awareness of such vulnerabilities can help promote the need for safe usage and better safeguards.



# Works Cited

<style>
  .works-cited {
    margin-left: 2em;
    text-indent: -2em;
    line-height: 1.5;
  }
</style>

<p class="works-cited">
Alawida, Moatsum, et al. <em>“Unveiling the Dark Side of ChatGPT: Exploring Cyberattacks and Enhancing User Awareness.”</em> Information, vol. 15, no. 1, Jan. 2024, p. 27. DOI.org
</p>
<p class="works-cited">
Bozic, Josip, and Franz Wotawa. “Interrogating Virtual Agents: In Quest of Security Vulnerabilities.” Testing Software and Systems, edited by Valentina Casola et al., vol. 12543, Springer International Publishing, 2020, pp. 20–34. DOI.org
</p>
<p class="works-cited">
Charfeddine, Maha, et al. “ChatGPT’s Security Risks and Benefits: Offensive and Defensive Use-Cases, Mitigation Measures, and Future Implications.” IEEE Access, vol. 12, 2024, pp. 30263–310. DOI.org
</p>
<p class="works-cited">
Espinha Gasiba, Tiago, et al. “May the Source Be with You: On ChatGPT, Cybersecurity, and Secure Coding.” Information, vol. 15, no. 9, Sep. 2024, p. 572. DOI.org
</p>
<p class="works-cited">
Gupta, Maanak, et al. “From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy.” IEEE Access, vol. 11, 2023, pp. 80218–45. DOI.org
</p>
<p class="works-cited">
Ibrar, Werisha, et al. “Generative AI: A Double-Edged Sword in the Cyber Threat Landscape.” Artificial Intelligence Review, vol. 58, no. 9, Jul. 2025, p. 285. DOI.org
</p>
<p class="works-cited">
Nobles, Calvin. “The Weaponization of Artificial Intelligence in Cybersecurity: A Systematic Review.” Procedia Computer Science, vol. 239, 2024, pp. 547–55. DOI.org
</p>
<p class="works-cited">
Nowrozy, Raza. “GPTs or Grim Position Threats? The Potential Impacts of Large Language Models on Non-Managerial Jobs and Certifications in Cybersecurity.” Informatics, vol. 11, no. 3, Jul. 2024, p. 45. DOI.org
</p>
<p class="works-cited">
Sebastian, Glorin. “Do ChatGPT and Other AI Chatbots Pose a Cybersecurity Risk?: An Exploratory Study.” International Journal of Security and Privacy in Pervasive Computing, vol. 15, no. 1, Mar. 2023, pp. 1–11. DOI.org
</p>
<p class="works-cited">
Sonkor, Muammer Semih, and Borja García De Soto. “Using ChatGPT in Construction Projects: Unveiling Its Cybersecurity Risks through a Bibliometric Analysis.” International Journal of Construction Management, vol. 25, no. 7, May 2025, pp. 741–49. DOI.org
</p>
